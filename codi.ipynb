{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codi.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "1951GUF2CAXb",
        "ML3sdL5DeaXN",
        "73UfDrXigM7U",
        "Nf2l6IK-pWT_",
        "3EaRGw1tRsLe",
        "b8nOOynww1El",
        "-miPNMjghjRZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gauthams1/codi/blob/master/codi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1951GUF2CAXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Libraries and mounting google drive "
      ]
    },
    {
      "metadata": {
        "id": "xu6aqJDwop3z",
        "colab_type": "code",
        "outputId": "b358e14f-0d31-45cd-f1b4-00f9b12dde74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "from google.colab import drive\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import add\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from numpy import random\n",
        "from numpy import array\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras.optimizers as optimizer\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import html\n",
        "import re\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yQWghuGCpV_7",
        "colab_type": "code",
        "outputId": "0d6981c9-1d4e-4b4a-d7c2-3412eb639bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ML3sdL5DeaXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# kaggle download"
      ]
    },
    {
      "metadata": {
        "id": "pXCDLnE8KB2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Questions=pd.read_csv('Questions.csv',encoding = 'iso-8859-1')\n",
        "Answers=pd.read_csv('Answers.csv',encoding = 'iso-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qx_8Uo81raB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Questions = Questions.sort_values(['Id'])[['Id','Score','Body','Title']]\n",
        "Answers = Answers.sort_values(['ParentId','Score'])[['ParentId','Score','Body']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73UfDrXigM7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pre processing "
      ]
    },
    {
      "metadata": {
        "id": "0JDSIJP4_ytB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is done to compile a dict of title question, answer body and answer code \n",
        "Questionbank=dict()\n",
        "cleanr = re.compile('(?i)<(?!code|/code).*?>')\n",
        "for  index, row in Questions.iterrows():\n",
        "  Questionbank[row['Id']]={'title':row['Title'],'body':re.sub('(?i)<(?!code|/code).*?>','',row['Body']),'result':list()}\n",
        "for index, row in Answers.iterrows():\n",
        "  if row['Score'] != 0:\n",
        "    Questionbank[row['ParentId']]['result'].append({'score':row['Score'],'body':re.sub('(?i)<(?!code|/code).*?>','',row['Body']) })\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsonzJLsWO6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Questions are parsed into code and Title of the question and answer code for predicting the title \n",
        "\n",
        "codes=list()\n",
        "for i in Questionbank:\n",
        "  for j in Questionbank[i]['result']:\n",
        "    code_list = re.findall(r'<code.*?>(.+?)</code>', j['body'],flags=re.DOTALL)\n",
        "    code_list = [html.unescape(x) for x in code_list if len(x) > 50 and len(x) < 1000 ]\n",
        "    if len(code_list) > 0 and j['score']>0 :\n",
        "      for code_ls in code_list:\n",
        "        codes.append({'title':Questionbank[i]['title'],'score':j['score'],'code':replace(code_ls)})\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkvE2oaffjo4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**reward is taken as the score of the answer so we compile this into 3 main array as below**"
      ]
    },
    {
      "metadata": {
        "id": "0MwCLdSwz4t-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "code_list = list()\n",
        "score_list = list()\n",
        "title_list = list()\n",
        "temp_code_list=list()\n",
        "temp_score_list=list()\n",
        "temp_title_list=list()\n",
        "for i in range(len(codes)):\n",
        "  title_list.append(\"(start) \"+codes[i]['title']+ \" (stop)\")\n",
        "  score_list.append(codes[i]['score'])\n",
        "  code_list.append(codes[i]['code'])\n",
        "token_title = token_create(title_list)\n",
        "token_code = token_create(code_list,' ')\n",
        "temp_seq_code = token_code.texts_to_sequences(code_list)\n",
        "temp_seq_title= token_title.texts_to_sequences(title_list)\n",
        "for i in range(len(codes)):\n",
        "\tif len(temp_seq_code[i]) > 5 and len(temp_seq_title[i]) > 2 :\n",
        "\t\ttemp_code_list.append(code_list[i])\n",
        "\t\ttemp_score_list.append(score_list[i])\n",
        "\t\ttemp_title_list.append(title_list[i])\n",
        "code_list = temp_code_list\n",
        "title_list = temp_title_list\n",
        "score_list = temp_score_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqZ_Jd0_gfNo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#save the initial Questionbank array\n",
        "!rm dict_pkl.pkl\n",
        "pickle.dump(Questionbank, open(\"dict_pkl.pkl\", \"wb\"))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0libZDqRdG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_dict = {\n",
        "    'code':code_list,\n",
        "    'score':score_list,\n",
        "    'title':title_list,\n",
        "    'token_title':token_title,\n",
        "    'token_code':token_code\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4OieZg7PhJTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm train_dict_pkl.pkl\n",
        "pickle.dump(training_dict, open(\"train_dict_pkl.pkl\", \"wb\"))  # save it into a file\n",
        "!cp train_dict_pkl.pkl drive/My\\ Drive/colabapp/codi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nf2l6IK-pWT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Functions\n"
      ]
    },
    {
      "metadata": {
        "id": "QLvDGBv2qMo6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def token_create(doc,avoid='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ '):\n",
        "  tokenizer = Tokenizer(num_words=5000,filters=avoid)\n",
        "  tokenizer.fit_on_texts(doc)\n",
        "  return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uv6YRZ6JHOgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embedding_dict(vocab_size,token):\n",
        "\tembeddings_index = dict()\n",
        "\tf = open('drive/My Drive/colabapp/codi/glove.6B.100d.txt')\n",
        "\tfor line in f:\n",
        "\t\tvalues = line.split()\n",
        "\t\tword = values[0]\n",
        "\t\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\t\tembeddings_index[word] = coefs\n",
        "\tf.close()\n",
        "\tembedding_matrix = zeros((vocab_size, 100))\n",
        "\tfor word, i in token.word_index.items():\n",
        "\t\tif i < vocab_size:\n",
        "\t\t\tembedding_vector = embeddings_index.get(word)\n",
        "\t\t\tif embedding_vector is not None:\n",
        "\t\t\t\tembedding_matrix[i] = embedding_vector\n",
        "\treturn embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "010cgbzO36Rf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_sequences(token_input,token_codes,doc_title,doc_code,max_inp,max_code,vocab_size_out):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\tseq_inp = token_input.texts_to_sequences([doc_code])[0]\n",
        "\tseq_out = token_codes.texts_to_sequences([doc_title])[0]\n",
        "\tfor i in range(1,len(seq_out)):\n",
        "\t\tin_seq,out_seq=seq_out[:i],seq_out[i]\n",
        "\t\tin_seq_2 = pad_sequences([in_seq], maxlen=max_code)[0]\n",
        "\t\tin_seq = pad_sequences([seq_inp], maxlen=max_inp)[0]\n",
        "\t\t# encode output sequence\n",
        "\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size_out)[0]\n",
        "\t\tX1.append(in_seq)\n",
        "\t\tX2.append(in_seq_2)\n",
        "\t\ty.append(out_seq)\n",
        "\treturn array(X1), array(X2), array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhnUQIG6XE_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seq_gen(mini,maxi,vocab_size_out):\n",
        "  while 1:\n",
        "    i = random.randint(mini,maxi)\n",
        "    x1,x2,y = create_sequences(token_title,token_code,title_list[i],code_list[i],max_len_input,max_len_output,5000)\n",
        "    # outputs request,probable answer,output\n",
        "    if x1.shape != (0,):\n",
        "      yield ([x2,x1],y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQuGxqxwRv3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_model(matrix,token_input,token_output,max_len_input,max_len_output):\n",
        "\tquestion_input = Input(shape=(max_len_input,))\n",
        "\tembeding = Embedding(5000, 100,weights=[matrix],trainable=False)(question_input)\n",
        "\tfe1 = Dropout(0.2)(embeding)\n",
        "\tfe2 = LSTM(1024,return_sequences=True)(fe1)\n",
        "\tfe2 = LSTM(1024,return_sequences=True)(fe2)\n",
        "\tfe2 = LSTM(1024,return_sequences=False)(fe2)\n",
        "\t# sequence model\n",
        "\tinputs2 = Input(shape=(max_len_output,))\n",
        "\tse1 = Embedding(5000, 256, mask_zero=True)(inputs2)\n",
        "\tse2 = Dropout(0.2)(se1)\n",
        "\tse3 = LSTM(1024,return_sequences=True)(se2)\n",
        "\tse3 = LSTM(1024,return_sequences=True)(se3)\n",
        "\tse3 = LSTM(1025,return_sequences=False)(se3)\n",
        "\t# decoder model\n",
        "\tdecoder1 = add([fe2, se3])\n",
        "\tdecoder2 = Dense(1024, activation='relu')(decoder1)\n",
        "\tdecoder3 = Dense(1024, activation='relu')(decoder2)\n",
        "\tdecoder4 = Dense(1024, activation='relu')(decoder3)\n",
        "\toutputs = Dense(5000, activation='softmax')(decoder4)\n",
        "\tmodel = Model(inputs=[question_input, inputs2], outputs=outputs)\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6rrwnHWm5Vcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "def replace(text):\n",
        "  rep = {'>>>': \"\",\n",
        "         '\\n': \" (newline) \",\n",
        "         '+':' ',\n",
        "         '.':' . ',\n",
        "         '-':' ',\n",
        "         '/':' ',\n",
        "         '*':' ',\n",
        "         '(':' ( ',\n",
        "         ')':' ) ',\n",
        "         '[':' [ ',\n",
        "         ']':' ] ',\n",
        "        ':':' : ',\n",
        "        ',':' , '} # define desired replacements here\n",
        "  rep = dict((re.escape(k), v) for k, v in rep.items())\n",
        "  pattern = re.compile(\"|\".join(rep.keys()))\n",
        "  text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)\n",
        "  text = re.sub('\\d+',' num ',text)\n",
        "  text = re.sub('\\'(.*?)\\'',' string ',text)\n",
        "  text = re.sub('\\\"(.*?)\\\"',' string ',text)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcsCsYSQCiET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def random_func(gamma):\n",
        "\twhile 1:\n",
        "\t\tpairs = next(source)\n",
        "\t\tfor i in range(9):\n",
        "\t\t\tpair2 = next(source)\n",
        "\t\t\tpairs = [[np.concatenate((pairs[0][0], pair2[0][0]), axis=0),np.concatenate((pairs[0][1], pair2[0][1]), axis=0)],np.concatenate((pairs[1], pair2[1]), axis=0)]\n",
        "\t\toutput_org = pairs[1]\n",
        "\t\tprev_max=0\n",
        "\t\toutput_pred = model2.predict(pairs[0])\n",
        "\t\tfor i in range(len(output_pred)-1,0,-1):\n",
        "\t\t\treward = 1\n",
        "\t\t\targ_org = argmax(output_org[i])\n",
        "\t\t\targ_pred = argmax(output_pred[i])\n",
        "\t\t\ttemp_max=np.max(output_pred[i])\n",
        "\t\t\tif (arg_org != arg_pred):\n",
        "\t\t\t\treward=0\n",
        "\t\t\tif reward == 0:\n",
        "\t\t\t\toutput_pred[i][arg_pred] = reward\n",
        "\t\t\t\toutput_pred[i][arg_org] = output_org[i][arg_org] \n",
        "\t\t\telse:\n",
        "\t\t\t\toutput_pred[i][arg_pred] = reward + gamma*prev_max\n",
        "\t\t\tprev_max=temp_max\n",
        "\t\tyield [pairs[0],output_pred]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EaRGw1tRsLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Import from saved files\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "hAsQXu-GjQ9k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "Questionbank = pickle.load(open('drive/My Drive/colabapp/codi/dict_pkl.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQ0EqdxCwzdM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "training_dict = pickle.load(open('drive/My Drive/colabapp/codi/train_dict_pkl.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b8nOOynww1El",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Initialize for training(both initial and continued)"
      ]
    },
    {
      "metadata": {
        "id": "YLhRBt-LIFxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "code_list,score_list,title_list,token_title,token_code = training_dict['code'],training_dict['score'],training_dict['title'],training_dict['token_title'],training_dict['token_code']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6JYVe1sVF6tG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_len_input = max([len(x) for x in token_title.texts_to_sequences(title_list)])\n",
        "max_len_output = max([len(x) for x in token_code.texts_to_sequences(code_list)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bvxzzGHIij5",
        "colab_type": "code",
        "outputId": "5f0b8fc8-60f7-4abb-a9d7-92c53b8f4c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(max_len_input)\n",
        "print(max_len_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-miPNMjghjRZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Initilize Model for training first time "
      ]
    },
    {
      "metadata": {
        "id": "0FOg8TS2Fxbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = define_model(embedding_weight,token_title,token_code,max_len_output,max_len_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfk6wd7nHsCP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e8MHqYj90wee",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer_1 = optimizer.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=optimizer_1, metrics=[ 'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jP9cMCPkA8Y0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_weight=embedding_dict(5000,token_title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Lpk_EqZh-2s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#For pretrained model"
      ]
    },
    {
      "metadata": {
        "id": "R9Gq65YCXL2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model2 = load_model('drive/My Drive/colabapp/codi/model3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPeAA9bs9IwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbCallBack = TensorBoard(log_dir='./log',\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=100,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Ene0uTTiO9E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Training"
      ]
    },
    {
      "metadata": {
        "id": "G_wQteQix1xe",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "d1766210-a374-4eeb-caba-e3919d9c8964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "for j in range(10,0,-1):\n",
        "\tsource= seq_gen(0,2000*(j+1),5000)\n",
        "\tsource2= seq_gen(2000*(j+1),2000*(j+2),5000)\n",
        "\tnext(random_func(0.9))\t\n",
        "\tprint('\\n---------dataset({}-{}) and ({}-{}) validation --------------------'.format(2000*j,2000*(j+1),2000*(j+1),2000*(j+2)))\n",
        "\tmodel2.fit_generator(random_func(0.9),steps_per_epoch=50, epochs=5,validation_data=source2, validation_steps=5,callbacks=[tbCallBack])\n",
        "\tmodel2.save(\"model3.h5\")\n",
        "\t!cp 'model3.h5' 'drive/My Drive/colabapp/codi/'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---------dataset(20000-22000) and (22000-24000) validation --------------------\n",
            "Epoch 1/5\n",
            "50/50 [==============================] - 522s 10s/step - loss: 8.5415 - acc: 0.2542 - val_loss: 5.1901 - val_acc: 0.1429\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 506s 10s/step - loss: 8.2465 - acc: 0.2624 - val_loss: 3.8943 - val_acc: 0.1852\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 508s 10s/step - loss: 8.2147 - acc: 0.2496 - val_loss: 4.4293 - val_acc: 0.2500\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 514s 10s/step - loss: 8.2686 - acc: 0.2475 - val_loss: 5.2695 - val_acc: 0.1765\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 494s 10s/step - loss: 8.0577 - acc: 0.2549 - val_loss: 4.0033 - val_acc: 0.2727\n",
            "\n",
            "---------dataset(18000-20000) and (20000-22000) validation --------------------\n",
            "Epoch 1/5\n",
            "37/50 [=====================>........] - ETA: 2:11 - loss: 7.6851 - acc: 0.2791"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HaqX99CqFh9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#logging"
      ]
    },
    {
      "metadata": {
        "id": "Jt2et4V5qDJ-",
        "colab_type": "code",
        "outputId": "f9596b7f-c80b-40e5-e474-a5fcd285bfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-15 14:58:39--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.203.53.176, 52.201.75.180, 52.200.123.104, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.203.53.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M   978KB/s    in 5.6s    \n",
            "\n",
            "2019-02-15 14:58:45 (928 KB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "haMWyA2HqQd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkXZRmE0qUfX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k0AiGpaVqWup",
        "colab_type": "code",
        "outputId": "7529b0fe-80c5-423d-ca3b-2fd3534951ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://79ed92ee.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}